{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset loader\n",
    "from data import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_dir = \"\" # test data mp3 경로 설정\n",
    "test_dataset = create_contrastive_datasets(dataset_dir)\n",
    "\n",
    "sample_rate = 44100  #[1, sample_rate*30]: 30초로 구간 설정\n",
    "test_contrastive_dataset = ContrastiveDataset(test_dataset,  input_shape=[1, sample_rate*30])\n",
    "\n",
    "batch_size = 68 \n",
    "test_loader = DataLoader(test_contrastive_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding 추출\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "stage1_model = torch.load('') #모델 경로 설정(.pth)\n",
    "stage1_model.eval() \n",
    "stage1_model.to(device)\n",
    "\n",
    "music_data = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    clip_a, clip_b, file_ids = batch\n",
    "    clip_a, clip_b= clip_a.to(device), clip_b.to(device)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        stage1_model = stage1_model.to(clip_a.device)\n",
    "        emb1,emb2 = stage1_model(clip_a, clip_b, device)\n",
    "        emb1 = emb1.cpu().numpy()\n",
    "\n",
    "    for file_id, embedding in zip(file_ids, emb1):\n",
    "        music_data.append({'id': file_id, 'embedding': embedding})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(music_data)\n",
    "df.to_csv(\"\", index=False) #.csv 파일 저장 경로 설정\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "- 임베딩 기준으로 코사인 유사도 계산 -> recall@k 계산\n",
    "1. threshold 값 정의 및 추천 곡 정의  \n",
    ": GT 유사도 값에서 threshold 값 이상의 노래들만 추천 노래로 봄\n",
    "  \n",
    "2. k개의 추천 곡 정의  \n",
    ": 임베딩 기준으로 코사인 유사도 계산해서, 상위 k개의 노래를 가져옴\n",
    "  \n",
    "3. k개의 추천 곡과 GT 추천 곡의 교집합   \n",
    ": 1번과 2번 곡의 공통된 곡의 개수를 셈\n",
    "  \n",
    "4. recall@k 계산   \n",
    ": 3번의 개수 / 1번의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gt : 앵커 노래 + threshold 유사도를 넘긴 나머지 노래"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 사이의 코사인 유사도 계산\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_sim_k(df, k=10):\n",
    "    \"\"\" 각 id의 embedding 벡터를 사용하여 코사인 유사도를 계산하고, 상위 n개 유사한 트랙을 반환 \"\"\"\n",
    "\n",
    "    # embedding 열을 numpy 배열로 변환\n",
    "    df[\"embedding\"] = df[\"embedding\"].apply(lambda x: np.array(x))\n",
    "\n",
    "    # 모든 트랙 id와 임베딩을 가져옴\n",
    "    track_ids = df[\"id\"].values\n",
    "    embeddings = np.stack(df[\"embedding\"].values)  # (num_samples, embedding_dim)\n",
    "\n",
    "    # 모든 트랙 간의 코사인 유사도 계산\n",
    "    cosine_sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    # 결과 저장 리스트\n",
    "    similarity_results = {}\n",
    "    \n",
    "    # 각 앵커 id에 대해 유사도가 높은 10개 트랙 찾기\n",
    "    for i, anchor_id in enumerate(track_ids):\n",
    "        similarities = cosine_sim_matrix[i]  # 현재 앵커와 모든 트랙 간 유사도 벡터\n",
    "        similarities[i] = -1 # 자기 자신 제외외\n",
    "        \n",
    "        # 유사도 높은 10개 트랙 선택\n",
    "        top_indices = np.argsort(similarities)[-1*k:][::-1]  # 내림차순 정렬\n",
    "        top_similarities = similarities[top_indices]  # 해당 유사도 값\n",
    "        top_track_ids = track_ids[top_indices]  # 해당 트랙 id\n",
    "        \n",
    "        # 결과 저장 (트랙 id, 유사도)\n",
    "        similarity_results[anchor_id] = [(track, float(sim)) for track, sim in zip(top_track_ids, top_similarities)] \n",
    "\n",
    "    return similarity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(predicted_sim, gt_df, k=10):\n",
    "    '''\n",
    "    input :\n",
    "    predicted_sim : dictionary (key:anchor_id, values:(track_id,sim_values))\n",
    "    gt_df : dataframe ('anchor_id': anchor_id, 'Track ID': {track_id : sim_value})\n",
    "    '''\n",
    "    anchor_ids = gt_df[\"anchor_id\"].values\n",
    "    ground_truth_sets = gt_df[\"Track ID\"].apply(eval).apply(set).values  # GT track_id의 sim values 집합\n",
    "    \n",
    "    recall_scores = []\n",
    "    for anchor_id, ground_truth in zip(anchor_ids, ground_truth_sets):\n",
    "        if anchor_id in predicted_sim:\n",
    "            pred_top_k = predicted_sim[anchor_id] \n",
    "            intersection = pred_top_k & ground_truth  # GT와 일치하는 예측 개수 (분자자)\n",
    "            recall = len(intersection) / len(ground_truth)  # Recall 계산\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "    return np.mean(recall_scores)  # 전체 평균 Recall@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall@k 실행 코드\n",
    "k = 10\n",
    "\n",
    "# 1. 모델 예측된 유사도 결과 계산\n",
    "predicted_sim = compute_sim_k(df, k=10)\n",
    "\n",
    "# 2. Ground Truth 데이터 로드\n",
    "gt_df = pd.read_csv(\"ground_truth.csv\")  # ground truth 파일 경로 설정\n",
    "\n",
    "# 3. Recall@10 계산\n",
    "recall_at_10 = calculate_recall_at_k(predicted_sim, gt_df, k=10)\n",
    "\n",
    "print(f\"Recall@10: {recall_at_10:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
