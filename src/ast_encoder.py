# -*- coding: utf-8 -*-
"""Ast_encoder.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F206fKiqSTw5n3fzPrtfggd_J4pYGXk2

1. data 16khz 로 바꾸기
2.  normalize the input to 0 mean and 0.5 std
* You can check ast/src/get_norm_stats.py to see how we compute the stats, or you can try using our AudioSet normalization input_spec = (input_spec + 4.26) / (4.57 * 2)

* Please note that AST needs smaller learning rate
"""


# !pip install transformers[torch] datasets[audio] audiomentations

# !pip install torch torchaudio

# !pip install "transformers[sentencepiece]"

from transformers import AutoFeatureExtractor, ASTModel
import torch
import torchaudio
import os

class ASTEncoder:
    def __init__(self, model_name="MIT/ast-finetuned-audioset-10-10-0.4593", sampling_rate=16000):
        self.sampling_rate = sampling_rate
        self.extractor = AutoFeatureExtractor.from_pretrained(model_name, sampling_rate=sampling_rate, do_normalize=True)  # 입력 16khz로 맞추기, normalize 진행
        self.model = ASTModel.from_pretrained(model_name)
        self.model.eval()

    def preprocess(self, audio_waves, min_length=400):
        embeddings = []

        for audio in audio_waves:
          #현재 window 사이즈 오류 뜨는 거 해겨해야 함
          input_values = self.extractor(audio)["input_values"]
          with torch.no_grad():
              output = self.model(input_values).last_hidden_state
          embeddings.append(output.squeeze().cpu().numpy())

        return embeddings


